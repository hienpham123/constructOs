import dotenv from 'dotenv';
import { readFileSync } from 'fs';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import pg from 'pg';

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

async function runSupabaseMigration() {
  // Supabase connection config
  const dbHost = process.env.DB_HOST || process.env.SUPABASE_DB_HOST;
  const dbPort = parseInt(process.env.DB_PORT || process.env.SUPABASE_DB_PORT || '5432');
  const dbUser = process.env.DB_USER || process.env.SUPABASE_DB_USER;
  const dbPassword = process.env.DB_PASSWORD || process.env.SUPABASE_DB_PASSWORD;
  const dbName = process.env.DB_NAME || process.env.SUPABASE_DB_NAME || 'postgres';

  if (!dbHost || !dbUser || !dbPassword) {
    console.error('‚ùå Missing Supabase database configuration!');
    console.error('\nPlease set the following environment variables:');
    console.error('  DB_HOST=your-project.supabase.co');
    console.error('  DB_PORT=5432 (or 6543 for IPv4)');
    console.error('  DB_USER=postgres.your-project-ref');
    console.error('  DB_PASSWORD=your-supabase-password');
    console.error('  DB_NAME=postgres');
    console.error('\nOr set them inline:');
    console.error('  DB_HOST=... DB_USER=... DB_PASSWORD=... npx tsx src/scripts/runTaskMigrationSupabase.ts');
    process.exit(1);
  }

  const dbConfig = {
    host: dbHost,
    port: dbPort,
    user: dbUser,
    password: dbPassword,
    database: dbName,
    ssl: { rejectUnauthorized: false }, // Supabase requires SSL
  };

  const client = new pg.Client(dbConfig);

  try {
    console.log('üîå Connecting to Supabase PostgreSQL...');
    console.log(`   Host: ${dbHost}:${dbPort}`);
    console.log(`   Database: ${dbName}`);
    console.log(`   User: ${dbUser}`);
    
    await client.connect();
    console.log('‚úÖ Connected to Supabase!\n');

    const migrationFile = join(__dirname, '../../../database/migrations/create_project_tasks_postgres.sql');
    console.log(`üìÑ Reading migration file: ${migrationFile}`);
    const sql = readFileSync(migrationFile, 'utf8');

    // Split SQL into statements
    const statements = sql
      .split(';')
      .map(s => s.trim())
      .filter(s => s.length > 0 && !s.startsWith('--') && !s.match(/^\s*$/));

    console.log(`üöÄ Executing ${statements.length} SQL statements...\n`);

    for (let i = 0; i < statements.length; i++) {
      const statement = statements[i];
      if (!statement) continue;

      try {
        await client.query(statement);
        console.log(`‚úÖ [${i + 1}/${statements.length}] Statement executed`);
      } catch (error: any) {
        // Ignore "already exists" errors
        if (error.message && (
          error.message.includes('already exists') ||
          error.message.includes('duplicate') ||
          error.message.includes('relation') ||
          error.message.includes('already defined')
        )) {
          console.log(`‚ö†Ô∏è  [${i + 1}/${statements.length}] Skipped (already exists)`);
        } else {
          console.error(`‚ùå [${i + 1}/${statements.length}] Error:`, error.message);
          // Don't throw, continue with other statements
          console.error(`   SQL: ${statement.substring(0, 100)}...`);
        }
      }
    }

    // Verify tables
    console.log('\nüîç Verifying tables...');
    const result = await client.query(`
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public'
      AND table_name IN ('project_tasks', 'task_activity')
      ORDER BY table_name
    `);

    const tableNames = result.rows.map(r => r.table_name);
    console.log(`\nüìä Found ${tableNames.length} tables:`);
    
    if (tableNames.includes('project_tasks')) {
      console.log('‚úÖ project_tasks - OK');
      
      // Check columns
      const columns = await client.query(`
        SELECT column_name, data_type 
        FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'project_tasks'
        ORDER BY ordinal_position
      `);
      console.log(`   Columns: ${columns.rows.length}`);
    } else {
      console.log('‚ùå project_tasks - NOT FOUND');
    }

    if (tableNames.includes('task_activity')) {
      console.log('‚úÖ task_activity - OK');
      
      // Check columns
      const columns = await client.query(`
        SELECT column_name, data_type 
        FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'task_activity'
        ORDER BY ordinal_position
      `);
      console.log(`   Columns: ${columns.rows.length}`);
    } else {
      console.log('‚ùå task_activity - NOT FOUND');
    }

    await client.end();
    console.log('\n‚ú® Supabase migration completed successfully!');
  } catch (error: any) {
    if (client) {
      try {
        await client.end();
      } catch (e) {
        // Ignore cleanup errors
      }
    }
    throw error;
  }
}

async function main() {
  try {
    await runSupabaseMigration();
    process.exit(0);
  } catch (error: any) {
    console.error('\n‚ùå Migration failed:', error.message);
    if (error.message.includes('connect')) {
      console.error('\nüí° Tips:');
      console.error('   1. Check your Supabase connection string');
      console.error('   2. Verify DB_HOST includes .supabase.co');
      console.error('   3. Check if your IP is whitelisted in Supabase dashboard');
      console.error('   4. For IPv4, use port 6543 instead of 5432');
    }
    process.exit(1);
  }
}

main();

